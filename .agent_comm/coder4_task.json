{
  "agent_id": "coder4",
  "task_id": "task_6",
  "files": [
    {
      "name": "loss_functions.py",
      "purpose": "Custom loss functions",
      "priority": "medium"
    },
    {
      "name": "evaluation.py",
      "purpose": "Model evaluation and metrics",
      "priority": "medium"
    }
  ],
  "project_info": {
    "project_name": "enhanced_cs.RO_2507.22546v1_Explainable_Deep_Anomaly_Detection_with_Sequential",
    "project_type": "computer_vision",
    "description": "Enhanced AI project based on cs.RO_2507.22546v1_Explainable-Deep-Anomaly-Detection-with-Sequential with content analysis. Detected project type: computer vision (confidence score: 8 matches).",
    "key_algorithms": [
      "Dataset",
      "Convolutional",
      "Wasmodelledasagaussianmixture",
      "Svm",
      "Theuseandevaluationofanexplainabledeepanomaly",
      "Classification",
      "Anomaly",
      "Inception-V3",
      "Automated",
      "Ing"
    ],
    "main_libraries": [
      "torch",
      "numpy",
      "pandas"
    ]
  },
  "paper_content": "PDF: cs.RO_2507.22546v1_Explainable-Deep-Anomaly-Detection-with-Sequential.pdf\nChunk: 1/1\n==================================================\n\n--- Page 1 ---\nExplainable Deep Anomaly Detection with\nSequential Hypothesis Testing for Robotic Sewer\nInspection\nAlex George1[0009\u22120008\u22125799\u22124161], Will Shepherd2[0000\u22120003\u22124434\u22129442], Simon\nTait2[0000\u22120002\u22120004\u22129555], Lyudmila Mihaylova1[0000\u22120001\u22125856\u22122223], and Sean\nR. Anderson1[0000\u22120002\u22127452\u22125681]\n1School of Electrical and Electronic Engineering, University of Sheffield, Sheffield,\nUK\n{ageorge4,l.s.mihaylova,s.anderson}@sheffield.ac.uk\n2School of Mechanical, Aerospace and Civil Engineering, University of Sheffield,\nSheffield, UK\n{w.shepherd,s.tait}@sheffield.ac.uk\nAbstract. Sewer pipefaults, such asleaks andblockages, canlead tose-\nvere consequences including groundwater contamination, property dam-\nage, and service disruption. Traditional inspection methods rely heavily\non the manual review of CCTV footage collected by mobile robots, which\nisinefficientandsusceptibletohumanerror.Toautomatethisprocess,we\npropose a novel system incorporating explainable deep learning anomaly\ndetectioncombinedwithsequentialprobabilityratiotesting(SPRT).The\nanomaly detector processes single image frames, providing interpretable\nspatial localisation of anomalies, whilst the SPRT introduces temporal\nevidence aggregation, enhancing robustness against noise over sequences\nof image frames. Experimental results demonstrate improved anomaly\ndetection performance, highlighting the benefits of the combined spatio-\ntemporal analysis system for reliable and robust sewer inspection.\nKeywords: Explainable Anomaly Detection \u00b7Deep Learning \u00b7Sewer\nInspection.\n1 Introduction\nSewer systems are key components of urban infrastructure, which enable the safe\ntransportationofwastewater. However, ageingpipelines, combinedwith environ-\nmental and human factors, lead to the formation of cracks, leaks, blockages, root\nintrusions and eventually collapses [9]. In the UK, around 300,000 sewer block-\nages occur annually, costing \u00a3100 million in repairs [1]. Traditional inspection\ntechniques rely on manual analysis of Closed-Circuit Television (CCTV) footage\ncollected by mobile robots, which is inefficient and prone to errors caused by\nfatigue and inconsistencies in interpretation by multiple operators [6]. The wa-\nter industry is therefore investigating the potential of automated pipe condition\nassessment techniques that alleviate these drawbacks [11].arXiv:2507.22546v1  [cs.RO]  30 Jul 2025\n\n--- Page 2 ---\n2 A. George et al.\nDeep learning classification algorithms have gained traction in research for\nsewerdefectdetectionandhavedemonstratedsuperiorperformancecomparedto\ntraditionalmachinelearningmethods[5,7,10].Modernexplainabledeepanomaly\ndetection methods, such as Fully Convolutional Data Description (FCDD) [8],\ncanofferadvantagesoverclassificationmethodsbypredictingthespatiallocation\nof anomalies in an input image, without requiring pixel-level labelled training\ndata.Thiscanenhancethesceneperceptionofautonomousmobilerobotsaswell\nas aid human operators in decision support. In addition, the fully convolutional\nnature of FCDD offers computational efficiency compared to post-processing ex-\nplainability methods like Grad-CAM [12], which necessitate additional backward\npasses through a classification network. Anomaly detection has been studied in\nsewerpipespreviouslyusingfeature-basedone-classclassifierssuchasGaborfea-\ntures with Support Vector Machines and Isolation Forests [3]. In this paper, we\npropose,forthefirsttime,theuseandevaluationofanexplainabledeepanomaly\ndetection system for sewer pipes based on FCDD, with feasibility evaluated on\na single specific anomaly class: deposits.\nA limitation of FCDD for analysing sewer CCTV is that it operates on single\nimage frames, disregarding the temporal dependencies in the video sequences.\nThis results in a potential loss of information from repeated observations of the\nsame anomaly, as well as a potential increase in decision errors due to transient\nnoise factors such as motion blur and variations in illumination [15]. To enhance\ntherobustnessofanomalydetection,weextendtheexplainableanomalydetector\nwith the Sequential Probability Ratio Test (SPRT), a sequential hypothesis test-\ning framework introduced by Wald [14]. SPRT enables robust decision-making\nby aggregating anomaly scores across multiple frames. Therefore, the complete\nsystem provides spatial localisation of faults and explainability via the deep\nanomaly detector, whilst the SPRT introduces temporal processing, enhancing\nrobustness against noise over image sequences.\nThe structure of this paper is as follows. In Section 2, we present the methods\nfor deep anomaly detection and SPRT as well as the publicly available sewer pipe\nCCTVdatasetsprovidedbytheWaterResearchCentre(WRc),hostedatSpring\n[13], and from the Integrated Civil and Infrastructure Research Centre (iCAIR)\nat the University of Sheffield, described in [2]. The results are then presented in\nSection 3, followed by a summary of the paper in Section 4.\n2 Methods\nTheproposedmethodologycombinesdeepanomalydetectionwithsequentialhy-\npothesistestingforrobustanomalydetection.AnFCDD-basedanomalydetector\nis used to generate the anomaly scores for normal and anomalous images along\nwith an explainable anomaly heatmap. The anomaly scores are then sequentially\naggregated using SPRT over time. By accumulating enough evidence, the system\ndecides whether to classify a temporal instance as normal or anomalous. This\ntwo-stage approach ensures that the defects are detected with confidence. The\nfollowing subsections cover the methodology in detail.\n\n--- Page 3 ---\nExplainable Deep Anomaly Detection with Sequential Hypothesis Testing 3\n2.1 Explainable Deep Anomaly Detection\nFig.1: FCDD architecture for explainable anomaly detection [8]\nWe used FCDD [8] to generate anomaly heatmaps Aand scalar anomaly\nscores zfrom input images X(Fig. 1), where\nA(X) =q\n\u03d5(X;W)2+ 1\u22121 (1)\nand\u03d5is a fully convolutional network (FCN) with weights W. The anomaly\nheatmap Ais upsampled using a strided transposed convolution with a Gaussian\nkernel to generate A\u2032, which has direct pixel-wise correspondence to X. The\nanomaly score zis obtained from the L1-norm of A,\nz=1\nu\u00b7v\u2225A\u22251(2)\nwhere uandvcorrespond to the dimensions of A.\nFCDD was trained using the following loss function,\nmin\nW1\nnnX\ni=1(1\u2212yi)1\nu\u00b7v\u2225A(Xi)\u22251\u2212yilog\u0012\n1\u2212exp\u0012\n\u22121\nu\u00b7v\u2225A(Xi)\u22251\u0013\u0013\n(3)\nwhere yi= 0indicates a normal sample and yi= 1indicates an anomaly. The\nfirst three stages of a pre-trained Inception-v3 network were used as a backbone\nfor FCDD. Training was performed using the Adam optimiser with a learning\nrateof 10\u22124andamini-batchsizeof32.Dataaugmentationtechniques(rotation,\ntranslation, jittering and noise) were applied randomly to 50% of the training\nimages. Anomaly score predictions using a calibration dataset were used to tune\na threshold parameter \u03c4using ROC curve analysis to determine normal (z < \u03c4 )\nand anomalous samples (z\u2265\u03c4).\n\n--- Page 4 ---\n4 A. George et al.\n2.2 Sequential Probability Ratio Test\nWe integrate time-dependent processing into anomaly detection using the Se-\nquential Probability Ratio Test (SPRT) framework [14]. SPRT is a form of\nsequential hypothesis testing that accumulates evidence from anomaly scores\nover time to determine if a normal ( H0) or anomalous ( H1) state is supported.\nLetz1, z2, ..., z trepresent the anomaly scores from the detector for video image\nframes up to time t. The cumulative sum of the log-likelihood ratio at time tis\nthen calculated as\n\u039bt=\u039bt\u22121+ logp(zt|H1)\np(zt|H0)(4)\nwhere p(zt|H1)andp(zt|H0)are the probability density functions (PDFs) of zt\nundereachhypothesis.Inthiscase, p(zt|H1)wasmodelledasaGaussianmixture\nmodel and p(zt|H0)was modelled as a gamma distribution.\nThe decision rule in SPRT is\n\u039bt\u2264a:accept H0and reject H1(Normal) (5)\n\u039bt\u2265b:accept H1and reject H0(Anomaly) (6)\na < \u039b t< b:continue monitoring (Undecided) (7)\nwhere aandbare the stopping bounds for accepting and rejecting a hypothesis.\nNote that \u039btis reinitialised to zero whenever a decision boundary is crossed.\nThe values for aandbare derived from the user-specified Type I error proba-\nbility ( \u03b1, or false positive rate) and Type II error probability ( \u03b2, or false negative\nrate), respectively, and are approximated as\na\u2248log\u03b2\n1\u2212\u03b1andb\u2248log1\u2212\u03b2\n\u03b1. (8)\nParameter selection for \u03b1and\u03b2involves a trade-off: \u03b1 < \u03b2minimises false\npositives at the cost of missed faults, while \u03b1 > \u03b2prioritises fault detection,\nwhilst potentially increasing false positives. In this investigation, we used \u03b1 < \u03b2\nto reduce false positives.\n2.3 Experimental Data\nThe FCDD network was trained and evaluated using two distinct publicly avail-\nable datasets: the single image frame WRc dataset [13] and the iCAIR video\ndataset [2]. For the WRc dataset, FCDD was trained in a one-vs-all framework\nwith 2500 anomaly (deposit) and 5005 normal (non-deposit) image frames. The\nmodel was calibrated on separate data (1001 anomaly, 1012 normal) and evalu-\nated on a further independent test set (2001 anomaly, 2006 normal). For bench-\nmarking, two binary Support Vector Machine (SVM) classifiers were also trained\nand evaluated on the WRc data, one employing Gabor features and the other\nutilising features extracted from a pre-trained Inception-v3 model. The iCAIR\nvideo dataset, featuring deposits as anomalies, was used to train (25 anomaly\nframes, 400 normal frames), calibrate (75 anomaly frames, 225 normal frames),\nand evaluate (5475 frames) FCDD and FCDD plus SPRT.\n\n--- Page 5 ---\nExplainable Deep Anomaly Detection with Sequential Hypothesis Testing 5\n(a)\n(b)\n (c)\n0 1 2 3\nAnomaly Score0123Probability DensityNormal Histogram\nAnomaly Histogram\nNormal Fitted PDF\nAnomaly Fitted PDF(d)\nFig.2:(a)Sewerinspectionrobot.(b)ExampleofCCTVimagewithanomaly.(c)\nCCTV image with anomaly heatmap overlay predicted by FCDD. (d) Anomaly\nscore distributions from the trained FCDD system, with fitted PDFs for normal\np(zt|H0)and anomalous distributions p(zt|H1).\n3 Results\nIn sewer CCTV inspection, a robot is typically used to capture image frames.\nFig. 2(a)-(c) shows the robot from the iCAIR study along with an example input\nimage frame Xcaptured by CCTV and an example of the anomaly heatmap\npredicted by FCDD, overlaid on the input image. Note that the spatial location\nof the deposit data is predicted in Fig. 2(c) by FCDD, even though it is not\nexplicitly trained to do this by pixel-wise labelling. A histogram of anomaly\nscores predicted by FCDD on the iCAIR calibration dataset for both normal\nand anomaly data are shown in Fig. 2(d).\nTo evaluate FCDD on single image frames, we used the large WRc dataset,\ncomparingSVMmodelstrainedonGaborfeaturesandInception-v3features.We\nchose the optimal threshold for FCDD to be the maximum of Youden\u2019s index,\ni.e. the point on the ROC curve (for the calibration data) with the maximum\ndifference between the true positive rate (TPR) and false positive rate (FPR).\nPerformance was substantially better using FCDD, with F1-scores of 88.03%\nusing FCDD vs 44.94% and 71.72% using the SVM models (Table 1).\nQuantitativeanalysisonthesmalleriCAIRvideodatasetonaper-framebasis\ndemonstrated improved F1-scores when combining FCDD with SPRT (94.36%)\nwhen \u03b1= 10\u22126and\u03b2= 0.01(chosen to demonstrate the effect of reducing\nfalse positives whilst maintaining detections), compared to simple thresholding\n(84.07% - Table 1). However, it should also be noted that the total frame count\n\n--- Page 6 ---\n6 A. George et al.\nusedinSPRT\u2019smetriccalculationswasreducedduetoundecidedframesbetween\nthreshold boundaries, thereby focusing the metrics on the quality of definitive\ndecisions. Fig. 3 demonstrates that SPRT reduces false alarms associated with\nsingle-frame thresholding, although misses one anomaly at approximately frame\n5600 due to lack of evidence. This illustrates the fundamental trade-off between\nthe choice of values for \u03b1and\u03b2to provide an optimal balance between deci-\nsion robustness gained through evidence accumulation and reduced sensitivity\nto fleeting or less persistent anomalies. The model and corresponding code are\nmade publicly available on GitHub [4].\nTable 1: Model performance comparison with WRc and iCAIR datasets\nDataset Method Accuracy Precision Recall (TPR) FPR F1-Score\nWRc SVM (Gabor) 62.94 87.07 30.28 4.4944.94\n(single SVM (Inception-v3) 76.24 88.42 60.32 7.88 71.72\nimages) FCDD (\u03c4= 1.09) 88.30 89.98 86.16 9.57 88.03\niCAIR FCDD (\u03c4= 0.64)88.79 79.69 88.96 11.30 84.07\n(video) FCDD+SPRT 96.47 97.85 91.12 0.96 94.36\nFrame\tNumber0 1000 2000 3000 4000 5000 6000NormalUndecidedAnomalyThreshold\tHits SPRT\tHits Ground\tTruth\nFig.3: Anomaly predictions for FCDD on the iCAIR video frames from thresh-\nolding ( \u03c4= 0.64, red) and SPRT ( \u03b1= 10\u22126, \u03b2= 0.01, green) overlaid on ground\ntruth (blue).\n4 Summary\nThis paper has proposed a novel sewer pipe fault detection system using ex-\nplainable deep anomaly detection, which can predict the spatial locations of\nanomalies. The deep anomaly detector was also combined with sequential hy-\npothesis testing via the SPRT. Experimental results demonstrated that FCDD\nimproved anomaly detection over an SVM method, and that SPRT enhanced\nthe robustness of anomaly detection by aggregating temporal information.\nAcknowledgments. ThisworkissupportedbytheEuropeanUnion\u2019sHorizonEurope\nResearch and Innovation Programme under Grant Agreement No. 101189847 - Pipeon.\nDisclosure of Interests. The authors have no competing interests to declare that\nare relevant to the content of this article.\n\n--- Page 7 ---\nExplainable Deep Anomaly Detection with Sequential Hypothesis Testing 7\nReferences\n1. Drinkwater, A., Moy, F.: Wipes in sewers blockage study (2017),\nhttps://www.water.org.uk/news-views-publications/publications/wipes-sewers-\nblockage-study, last accessed 2025/03/24\n2. Edwards, S., Zhang, R., Worley, R., Mihaylova, L., Aitken, J., Anderson, S.R.: A\nrobust method for approximate visual robot localization in feature-sparse sewer\npipes. Frontiers in Robotics and AI 10, 1150508 (2023)\n3. Fang, X., Guo, W., Li, Q., Zhu, J., Chen, Z., Yu, J., Zhou, B., Yang, H.: Sewer\npipelinefaultidentificationusinganomalydetectionalgorithmsonvideosequences.\nIEEE Access 8, 39574\u201339586 (2020)\n4. George, A.: Explainable-Anomaly-Detection-SPRT (2025), https://github.com/\nalexgeorge13/Explainable-Anomaly-Detection-SPRT, last accessed 2025/07/24\n5. Haurum, J.B., Moeslund, T.B.: Sewer-ml: A multi-label sewer defect classification\ndataset and benchmark. In: Proceedings of the IEEE/CVF Conference on Com-\nputer Vision and Pattern Recognition (CVPR). pp. 13456\u201313467 (June 2021)\n6. Kumar, S.S., Wang, M., Abraham, D.M., Jahanshahi, M.R., Iseley, T., Cheng,\nJ.C.: Deep learning\u2013based automated detection of sewer defects in CCTV videos.\nJournal of Computing in Civil Engineering 34(1), 04019047 (2020)\n7. Li,Y.,Wang,H.,Dang,L.M.,Song,H.K.,Moon,H.:Vision-baseddefectinspection\nand condition assessment for sewer pipes: A comprehensive survey. Sensors 22(7),\n2722 (2022)\n8. Liznerski, P., Ruff, L., Vandermeulen, R.A., Franks, B.J., Kloft, M., Muller, K.R.:\nExplainable deep one-class classification. In: International Conference on Learning\nRepresentations (2021)\n9. Malek Mohammadi, M., Najafi, M., Kermanshachi, S., Kaushal, V., Sera-\njiantehrani, R.: Factors influencing the condition of sewer pipes: State-of-the-art\nreview. Journal of Pipeline Systems Engineering and Practice 11(4), 03120002\n(2020)\n10. Pouyanfar, S., Sadiq, S., Yan, Y., Tian, H., Tao, Y., Reyes, M.P., Shyu, M.L.,\nChen, S.C., Iyengar, S.S.: A survey on deep learning: Algorithms, techniques, and\napplications. ACM computing surveys (CSUR) 51(5), 1\u201336 (2018)\n11. Rayhana, R., Jiao, Y., Zaji, A., Liu, Z.: Automated vision systems for condition\nassessmentofsewerandwaterpipelines.IEEETransactionsonAutomationScience\nand Engineering 18(4), 1861\u20131878 (2020)\n12. Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D.: Grad-\nCAM: Visual explanations from deep networks via gradient-based localization. In:\nProceedings of the IEEE International Conference on Computer Vision. pp. 618\u2013\n626 (2017)\n13. Spring: Spring Innovation - Accelerating Water Sector Transformation.\nhttps://spring-innovation.co.uk, last accessed 2025/07/16\n14. Wald, A.: Sequential tests of statistical hypotheses. In: Breakthroughs in statistics:\nFoundations and basic theory, pp. 256\u2013298. Springer (1992)\n15. Zhao, M., Liu, Y., Liu, J., Zeng, X.: Exploiting spatial-temporal correlations for\nvideoanomalydetection.In:202226thInternationalConferenceonPatternRecog-\nnition (ICPR). pp. 1727\u20131733. IEEE (2022)",
  "project_dir": "artifacts/projects/enhanced_cs.RO_2507.22546v1_Explainable_Deep_Anomaly_Detection_with_Sequential",
  "communication_dir": "artifacts/projects/enhanced_cs.RO_2507.22546v1_Explainable_Deep_Anomaly_Detection_with_Sequential/.agent_comm",
  "assigned_at": "2025-07-31T22:08:29.352712",
  "status": "assigned"
}